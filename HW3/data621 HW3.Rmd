---
title: "data621 HW3"
author: "jim lung"
date: "April 5, 2018"
output:
  word_document: default
  pdf_document: default
  tidy: yes
  html_document:
    highlight: pygments
    theme: cerulean
code_folding: hide
---



```{r setup, include=FALSE}

options(warn = -1)

suppressMessages(require(plotly))
library(knitr)
suppressMessages(library(RCurl))
suppressMessages(library(plyr))
suppressMessages(library(ggplot2))
suppressMessages(library(plotly))
suppressMessages(require(scatterplot3d))
suppressMessages(library(Amelia))
suppressMessages(library(ROCR))
suppressMessages(library(pROC))
suppressMessages(library(corrplot));

crime <- read.csv("https://raw.githubusercontent.com/fung1091/data621/master/HW3/crime-training-data_modified.csv", header = TRUE, sep = ",")

crime_evaluation <- read.csv("https://raw.githubusercontent.com/fung1091/data621/master/HW3/crime-evaluation-data_modified.csv", header = TRUE, sep = ",")


```



## 1. Data Exploration:

Analyzing the overall data to see if there is any discrepancies there as missing data or there is any need for data transformation


```{R}
names(crime)
str(crime)
dim(crime)
kable(summary(crime))

```

### We observed that:

* The crime dataset contains 13 variables, with 466 observations

* There are no missing values.

* The Minimum, Quatiles and Maximum values.

* Since this is logistic regression we don't have to worry about the normal distribution of data and no transformation is needed


## 2. Data Preparation

### There is no major data preparation effort is needed as this is a logistic regression and more over there is no missing data in the dataset.


```{r}
## checkin no missing data
sapply(crime, function(x) sum(is.na(x)))
sapply(crime_evaluation, function(x) sum(is.na(x)))

```

## 3. Build Models
### Consdering target as a response variable (Independent variable), lets pair it with complete data set and also find the best fit model using GLM package

```{R}
pairs(crime, col=crime$target)

```

### Simple regression model

```{R}
fit <- glm(target ~., data = crime) 
summary(fit)
par(mfrow=c(2,2))
plot(fit)
```

Simple regression model using glm package shows that the p value for zn,indus,chas, rm,dis, tax, ptratio,black ,lstat are more than the significance value of 0.05, so they are not contributing much to the target (independent variable)

So, lets move to the logistic regression for binomial distribution where we can see the variables interdependent on the independent variable target and get teh best fit subset of the crime dataset

### Using Logistics regression for a better results as

```{r}

crimetarget <- glm(target~., family=binomial(link='logit'),data=crime)

summary(crimetarget)
par(mfrow=c(2,2))
plot(crimetarget)

```

The variables like zn, indus, chas,rm and lstat are not statistically significant due to their p-value being greater than statiscally accepted p-value of 0.05, So we have a scope to refine the model without these variables and repeat the best fit logistic regression and build a preditive model.

Null deviance is 645.88 to imply if all other parameters are held constant(control or not included), the estimate would be 645.88, while the Residual deviance of 186.15 means with the imclusion of other estimator, we expect the deviance to be 186.14.

AIC is 214,15 and signifies the best fit quality of the model compared to other similar model available. If we are comparing with other models, best model should have lowest deviance and AIC value.

The greater the difference between the Null deviance and Residual deviance, the better.


### The Analysis of Variance (ANOVA)
To confirm if we have concluded the significance of varaibles correctly or not

```{R}
anova(crimetarget, test="Chisq")
```

It shows that the chas, age and lstat has no significance and rest all are contributing towards target variable. So lets run the best fit model keeping significant variables.


```{r}
crime2 <- subset(crime, select = -c(zn,indus,chas,rm,lstat))

crimetarget2 <- glm(target~., family=binomial(link='logit'),data=crime2)
summary(crimetarget2)
par(mfrow=c(2,2))
plot(crimetarget2)

anova(crimetarget2, test="Chisq")

```

age, dis are not significantly contributing to the target variable as it's p value is more than the significance value, so lets remove that from the next iteration 

```{r}
crime3 <- subset(crime2, select = -c(age, dis))

crimetarget3 <- glm(target~., family=binomial(link='logit'),data=crime3)
summary(crimetarget3)
par(mfrow=c(2,2))
plot(crimetarget3)

anova(crimetarget3, test="Chisq")

```

crimetarget3 model has nox,black, rad, tax, ptratio and medv as the significant variables and contrbuting to the target as key variable predicting crime in that area

## 4. Selection Models

## Predictive model for crimetarget model
```{R}

pred <- predict(crimetarget, type="response")
pred2 <- prediction(pred, crime$target)
pred3 <- performance(pred2, measure = "tpr", x.measure = "fpr")
plot(pred3)
```

Above is the plot for Sensitivity and Specitivity for the city target, while the value below is it AUC.

```{R}
auc <- performance(pred2, measure = "auc")
auc <- auc@y.values[[1]]
auc
```


### Predictions and Accuracy for crimetarget model

```{r}

target_predicts <- predict(crimetarget,newdata=subset(crime,select=c(1,2,3,4,5,6,7,8,9,10,11,12,13)),type='response')
target_predicts <- ifelse(target_predicts > 0.5,1,0)

attach(crime)

CM1<-table(target_predicts, target)
Pos_Pos=CM1[1,1]
Pos_Neg=CM1[1,2]
Neg_Pos=CM1[2,1]
Neg_Neg=CM1[2,2]

Specificity= Neg_Neg/(Pos_Neg+Neg_Neg)
Sensitivity= Pos_Pos/(Pos_Pos+Neg_Pos)
Pos_Pred_Val= Pos_Pos/(Pos_Pos+Pos_Neg)
Neg_Pred_Val=Neg_Neg/(Neg_Pos+Neg_Neg)

misClasificError <- mean(target_predicts != target)
Accuracy=1-misClasificError

print(paste('Accuracy',1-misClasificError))

BestFitModel1<- data.frame(auc,Specificity,Sensitivity,Accuracy,Pos_Pred_Val,Neg_Pred_Val)

```

## Predictive model for crimetarget2 model

```{R}

pred <- predict(crimetarget2, type="response")
pred2 <- prediction(pred, crime$target)
pred3 <- performance(pred2, measure = "tpr", x.measure = "fpr")
plot(pred3)
```

Above is the plot for Sensitivity and Specitivity for the city target, while the value below is it AUC.

```{R}
auc <- performance(pred2, measure = "auc")
auc <- auc@y.values[[1]]
auc
```


### Predictions and Accuracy for crimetarget2 model

```{R}


target_predicts <- predict(crimetarget2,newdata=crime,type='response')
target_predicts <- ifelse(target_predicts > 0.5,1,0)

attach(crime)

CM1<-table(target_predicts, target)
Pos_Pos=CM1[1,1]
Pos_Neg=CM1[1,2]
Neg_Pos=CM1[2,1]
Neg_Neg=CM1[2,2]

Specificity= Neg_Neg/(Pos_Neg+Neg_Neg)
Sensitivity= Pos_Pos/(Pos_Pos+Neg_Pos)
Pos_Pred_Val= Pos_Pos/(Pos_Pos+Pos_Neg)
Neg_Pred_Val=Neg_Neg/(Neg_Pos+Neg_Neg)

misClasificError <- mean(target_predicts != target)
Accuracy=1-misClasificError

print(paste('Accuracy',1-misClasificError))

BestFitModel2<- data.frame(auc,Specificity,Sensitivity,Accuracy,Pos_Pred_Val,Neg_Pred_Val)

```


## Predictive model for crimetarget3 model
```{R}

pred <- predict(crimetarget3, type="response")
pred2 <- prediction(pred, crime$target)
pred3 <- performance(pred2, measure = "tpr", x.measure = "fpr")
plot(pred3)
```

Above is the plot for Sensitivity and Specitivity for the city target, while the value below is it AUC.

```{R}
auc <- performance(pred2, measure = "auc")
auc <- auc@y.values[[1]]
auc
```


### Predictions and Accuracy.

```{R}


target_predicts <- predict(crimetarget3,newdata=crime,type='response')
target_predicts <- ifelse(target_predicts > 0.5,1,0)

attach(crime)

CM1<-table(target_predicts, target)
Pos_Pos=CM1[1,1]
Pos_Neg=CM1[1,2]
Neg_Pos=CM1[2,1]
Neg_Neg=CM1[2,2]

Specificity= Neg_Neg/(Pos_Neg+Neg_Neg)
Sensitivity= Pos_Pos/(Pos_Pos+Neg_Pos)
Pos_Pred_Val= Pos_Pos/(Pos_Pos+Pos_Neg)
Neg_Pred_Val=Neg_Neg/(Neg_Pos+Neg_Neg)

misClasificError <- mean(target_predicts != target)
Accuracy=1-misClasificError

print(paste('Accuracy',1-misClasificError))

BestFitModel3<- data.frame(auc,Specificity,Sensitivity,Accuracy,Pos_Pred_Val,Neg_Pred_Val)
```

##Compare the Models to choose the best

```{r}

CompareBestFitModel=rbind(BestFitModel1,BestFitModel2,BestFitModel3)
colnames(CompareBestFitModel)=c("AUC","Specificity","Sensitivity","Accuracy","Pos_Pred_Val","Neg_Pred_Val")
rownames(CompareBestFitModel)=c("Model1","Model2","Model3")
CompareBestFitModel

```

## Conclusion

From the above analysis, we can deduce that the AUC ( Area Under Curve) for all the three models are very close to 1, which indicate that the model 1 is more specificity, sensitivity and accuracy.

And the nox, rad, tax, pratio, black and medv contributed significantly to the increasing crime rate of the city under observation.